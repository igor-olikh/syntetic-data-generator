llm:
  provider: "openai"

openai:
  api_base: "http://localhost:11434/v1"
  api_key: "ollama"
  model: "llama3.2:3b"

generation:
  temperature: 0.7
  chunk_size: 4000
  num_pairs: 25

curate:
  threshold: 7.0
  batch_size: 8

