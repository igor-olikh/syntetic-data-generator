# =================================================================
# Configuration for the Synthetic Data Generation Kit
# =================================================================

llm:
  provider: "api-endpoint"

api-endpoint:
  api_base: "https://api.openai.com/v1"
  api_key: "[YOUR-API-KEY]"
  model: "gpt-4o"

# -----------------------------------------------------------------
# Generation Parameters
# -----------------------------------------------------------------
generation:
  # Number of CPU cores to use for parallel processing
  # Set to -1 to use all available cores
  num_workers: 4

  # Number of examples to generate per batch. This is what the LLM sees at once.
  batch_size: 4

  # Parameters for controlling the LLM's output
  temperature: 0.8
  top_p: 0.95

# -----------------------------------------------------------------
# Data and File Paths
# -----------------------------------------------------------------
# Path to your prompt template file. You will need to create this.
# See Step 2 below.
prompt_template_file: "prompt_template.txt"

# Optional: A file containing variables to be substituted into the prompt.
# Useful for generating varied data from a list of topics, names, etc.
# variable_file: "variables.csv"

# -----------------------------------------------------------------
# Storage Configuration
# -----------------------------------------------------------------
storage:
  # The file where your generated synthetic data will be saved
  output_file: "generated_data.jsonl"

  # How many generated examples to keep in memory before flushing to the output file
  # A larger number can be faster but uses more RAM.
  cache_size: 100